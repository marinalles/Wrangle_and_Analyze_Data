{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The dataset that will be wrangled and analysed is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. The dataset provides information about around 2,300 tweets. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10 and numerators are almost always greater than 10, like 11/10, 12/10, 13/10, etc.That is because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gathering data\n",
    "\n",
    "In this part the different documents that were needed for this project were gathered:\n",
    "\n",
    "- **twitter-archive-enhanced.csv:** the WeRateDogs Twitter archive with a lot of information such as the dog stage, the text of the images and the source.\n",
    "- **image_predictions.tsv:** the tweet image predictions with the predicted dog breeds in each of the predictions (total of 3), jointly with the probability that the prediction was correct.\n",
    "- **tweet-json.txt:** json data of the information downloaded from the API of Twitter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assessing data\n",
    "\n",
    "Once all the data was gathered, the assessment was done for the three datasets: archive, img_pred and api. It was a dirty and messy dataset that had a lot of issues and not all of them were assessed. The assessment was done firstly visually and then programatically to detect the following quality and tidiness issues:\n",
    "\n",
    "- **Quality issues**\n",
    "    - Q1. Wrong expanded URLs in archive\n",
    "    - Q2. Incorrect datatype of timestamp in archive it should be a datatype64\n",
    "    - Q3. The retweets in archive are not needed for the analysis\n",
    "    - Q4. Wrong value of rating_denominator in archive it should be always 10\n",
    "    - Q5. Breed dog names are in lowercase in img_pred\n",
    "    - Q6. Missing values in some columns in archive in in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id and retweeted_status_timestamp\n",
    "    - Q7. Wrong datatype for tweet_id in archive, img_pred and api it should be a string instead of an integer\n",
    "    - Q8. Difficult to read the long values of the column source in archive\n",
    "\n",
    "- **Untidy data**\n",
    "    - U1. There are 4 columns (doggo, floffer, pupper and puppo) in archive to refer to the dog stage\n",
    "    - U2. Three tables with the same tweet_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cleaning data\n",
    "\n",
    "In this step a copy of the datasets was done in case the original data was needed. The data was cleaned based on the issues found in the data assessment by defining the issue and how it could be solved, coding and finally testing if the results were the wanted ones. In the coding step some useful links were searched in order to learn how to solve som issues or trying to be more efficient (doing the same but with a shorter code). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
